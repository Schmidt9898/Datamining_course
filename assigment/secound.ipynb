{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.decomposition import PCA,KernelPCA\n",
    "\n",
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier as DTC\n",
    "from sklearn.linear_model import LinearRegression as LR\n",
    "from sklearn.metrics import accuracy_score as acc\n",
    "from sklearn.metrics import balanced_accuracy_score as bas\n",
    "from sklearn.metrics import plot_confusion_matrix as pcm\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn import linear_model\n",
    "import sweetviz as sv\n",
    "\n",
    "\n",
    "def f_measure(recall,precision):\n",
    "\treturn (1+3*3)* (recall*precision) / ((3*3*recall) + precision) \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain the data for linear regression\n",
    "\n",
    "x_train = pd.read_csv('data/X_train.csv')\n",
    "y_train = pd.read_csv('data/y_train.csv')\n",
    "unknown = pd.read_csv('data/X_test.csv')\n",
    "\n",
    "\n",
    "#train_report = sv.analyze(x_train)\n",
    "#train_report.show_html(\"train_report.html\",open_browser=True)\n",
    "\n",
    "x_train.drop('Id', inplace=True, axis=1)\n",
    "#x_train = pd.get_dummies(x_train)\n",
    "#print(\"isnasum \",x_train.isna().sum())\n",
    "x_train = x_train.fillna(0)\n",
    "\n",
    "unknown.drop('Id', inplace=True, axis=1)\n",
    "#unknown = pd.get_dummies(unknown)\n",
    "unknown = unknown.fillna(0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "x_train.columns\n",
    "\n",
    "visited = []\n",
    "\n",
    "for col in x_train.columns:\n",
    "\tsimbol = col[0:2]\n",
    "\tif simbol in visited:\n",
    "\t\tcontinue\n",
    "\tvisited.append(simbol)\n",
    "\t#print(simbol)\n",
    "\tsim_cols = []\n",
    "\t#get all similar colum\n",
    "\tfor col2 in x_train.columns:\n",
    "\t\tif simbol in col2:\n",
    "\t\t\tsim_cols.append(col2)\n",
    "\t\n",
    "\tif len(sim_cols) > 1:\n",
    "\t\t#print(len(sim_cols))\n",
    "\t\tdata = x_train[sim_cols] \n",
    "\t\tdata = data.div(data.sum(axis=1),axis = 0)\n",
    "\t\tx_train[sim_cols] = data \n",
    "\t\t#break\n",
    "\n",
    "\t\t#= x_train[sim_cols] / 10\n",
    "\t\t#print(x_train[sim_cols])\n",
    "\t#print(sim_cols)\n",
    "\n",
    "\n",
    "\n",
    "#x_train.iloc[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_train, y_train,test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "train_res = y_train \n",
    "test_res = y_test\n",
    "\n",
    "#train_data, test_data, train_res, test_res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unknown = pd.read_csv('data/X_test.csv')\n",
    "unknown.drop('Id', inplace=True, axis=1)\n",
    "#unknown = pd.get_dummies(unknown)\n",
    "unknown = unknown.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = x_train.columns\n",
    "\n",
    "new_cols = []\n",
    "for c in col:\n",
    "\ttag = c.split('_')[0]\n",
    "\tcount=0\n",
    "\tfor name in col:\n",
    "\t\tif tag in name:\n",
    "\t\t\tcount+=1\n",
    "\tif count == 1:\n",
    "\t\tnew_cols.append(c) \n",
    "\t\t#print(c)\n",
    "\t#if [c==x for x in col]\n",
    "\n",
    "train_data = x_train[new_cols]\n",
    "test_data = x_test[new_cols]\n",
    "\n",
    "print(len(new_cols))\n",
    "\n",
    "unknown_data = unknown[new_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(x_train.columns))\n",
    "#print(x_train.columns)\n",
    "#does the same as next\n",
    "#x_train.nunique()\n",
    "#print(\"isnasum \",x_train.isna().sum())\n",
    "headers = []\n",
    "\n",
    "for col in x_train.columns:\n",
    "\t#if not \"000\" in col:\n",
    "\t\t#print(col,(x_train[col] == 0).sum())\n",
    "\t\t#continue\n",
    "\t\t#print(col)\n",
    "\tif (x_train[col] == 0).sum() < len(x_train)/2:\n",
    "\t\t#print(col,(x_train[col] == 0).sum(),len(x_train[col].value_counts()))\n",
    "\t\theaders.append(col)\n",
    "\n",
    "#for col in x_train.columns:\n",
    "#\tif len(x_train[col].value_counts()) < len(x_train)/2:\n",
    "#\t\theaders.append(col)\n",
    "\t\t#print(col,len(x_train[col].value_counts()))\n",
    "\n",
    "\n",
    "train_data = x_train[headers]\n",
    "test_data = x_test[headers]\n",
    "\n",
    "print(len(headers))\n",
    "\n",
    "unknown_data = unknown[headers]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dont run this\n",
    "train_data = x_train\n",
    "test_data = x_test\n",
    "unknown_data = unknown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clf_dtc = DTC(random_state=42,criterion = \"entropy\",min_samples_split = 50,max_features = \"sqrt\")#\"entropy\"  #log_loss #gini\n",
    "clf_dtc.fit(train_data,train_res)\n",
    "predicted_Y = clf_dtc.predict(test_data)\n",
    "#Y_test_proba = clf_dtc.predict_proba(test_data)[:,1]\n",
    "\n",
    "#predicted_Y = [ i>0.2 for i in Y_test_proba]\n",
    "\n",
    "print(\"acc,\",acc(test_res,predicted_Y))\n",
    "print(\"bas,\",bas(test_res,predicted_Y))\n",
    "pcm(clf_dtc,test_data,test_res)\n",
    "error = 0\n",
    "for i in range(len(test_res)):\n",
    "\tif test_res._values[i] != predicted_Y[i]:\n",
    "\t\t#print(test_res._values[i],predicted_Y[i],Y_test_proba[i])\n",
    "\t\terror += 1 \n",
    "print(\"Error,\",error)\n",
    "print(\"F3,\",fbeta_score(test_res, predicted_Y, average='binary', beta=3))\n",
    "recall = recall_score(test_res,predicted_Y)\n",
    "precision = precision_score(test_res,predicted_Y)\n",
    "print(\"precision,\",precision)\n",
    "print(\"recall,\",recall)\n",
    "#print(\"f_measure\",f_measure(recall,precision))\n",
    "\n",
    "predicted_Y = clf_dtc.predict(unknown_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_knc = KNeighborsClassifier(2,algorithm=\"auto\") \n",
    "#DTC(random_state=42,criterion = \"gini\",min_samples_split = 50,max_features = \"sqrt\")#\"entropy\"  #log_loss\n",
    "\n",
    "clf_knc.fit(train_data,train_res)\n",
    "predicted_Y = clf_knc.predict(test_data)\n",
    "\n",
    "print(\"acc,\",acc(test_res,predicted_Y))\n",
    "print(\"bas,\",bas(test_res,predicted_Y))\n",
    "error = 0\n",
    "for i in range(len(test_res)):\n",
    "\tif test_res._values[i] != predicted_Y[i]:\n",
    "\t\t#print(test_res._values[i],predicted_Y[i],Y_test_proba[i])\n",
    "\t\terror += 1 \n",
    "print(\"Error,\",error)\n",
    "print(\"F3,\",fbeta_score(test_res, predicted_Y, average='binary', beta=3))\n",
    "recall = recall_score(test_res,predicted_Y)\n",
    "precision = precision_score(test_res,predicted_Y)\n",
    "print(\"precision,\",precision)\n",
    "print(\"recall,\",recall)\n",
    "pcm(clf_knc,test_data,test_res)\n",
    "\n",
    "\n",
    "#predicted_Y = clf.predict(Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100,bootstrap=True)\n",
    "clf.fit(train_data,train_res)\n",
    "predicted_Y = clf.predict(test_data)\n",
    "Y_test_proba = clf.predict_proba(test_data)[:,1]\n",
    "\n",
    "print(\"acc,\",acc(test_res,predicted_Y))\n",
    "print(\"bas,\",bas(test_res,predicted_Y))\n",
    "error = 0\n",
    "for i in range(len(test_res)):\n",
    "\tif test_res._values[i] != predicted_Y[i]:\n",
    "\t\t#print(test_res._values[i],predicted_Y[i],Y_test_proba[i])\n",
    "\t\terror += 1 \n",
    "print(\"Error,\",error)\n",
    "print(\"F3,\",fbeta_score(test_res, predicted_Y, average='binary', beta=3))\n",
    "recall = recall_score(test_res,predicted_Y)\n",
    "precision = precision_score(test_res,predicted_Y)\n",
    "print(\"precision,\",precision)\n",
    "print(\"recall,\",recall)\n",
    "pcm(clf,test_data,test_res)\n",
    "predicted_Y = clf.predict(unknown_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=10)\n",
    "pca = pca.fit(train_data)\n",
    "train_pca = pca.transform(train_data)\n",
    "\n",
    "test_pca = pca.transform(test_data)\n",
    "\n",
    "#Real_pca = pca.transform(Test)\n",
    "\n",
    "#reg = linear_model.BayesianRidge()\n",
    "\n",
    "#plt.scatter(train_pca)\n",
    "plt.scatter(train_pca[:,1],train_pca[:,6],c=train_res)\n",
    "plt.show()\n",
    "\n",
    "#clf = DTC(random_state=42,criterion = \"gini\",min_samples_split = 100,max_features = \"sqrt\")#\"entropy\"  #log_loss\n",
    "#clf = clf.fit(train_pca,test_res)\n",
    "#reg = reg.fit(train_pca,y_train)\n",
    "\n",
    "#print(reg.coef_)\n",
    "\n",
    "#predicted_Y = clf.predict(test_pca)\n",
    "#predicted_Y = reg.predict(test_pca)\n",
    "#Y_test_proba = clf.predict_proba(test_pca)[:,1]\n",
    "\n",
    "\n",
    "#print(acc(test_res,predicted_Y))\n",
    "\n",
    "#print(bas(test_res,predicted_Y,adjusted=True))\n",
    "#print(bas(test_res,predicted_Y,adjusted=False))\n",
    "\n",
    "#pcm(clf,train_pca,y_train)\n",
    "\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=20)\n",
    "clf.fit(train_pca,train_res)\n",
    "predicted_Y = clf.predict(test_pca)\n",
    "Y_test_proba = clf.predict_proba(test_pca)[:,1]\n",
    "\n",
    "#predicted_Y = [ i>0.2 for i in Y_test_proba]\n",
    "\n",
    "\n",
    "print(\"acc,\",acc(test_res,predicted_Y))\n",
    "print(\"bas,\",bas(test_res,predicted_Y))\n",
    "error = 0\n",
    "for i in range(len(test_res)):\n",
    "\tif test_res._values[i] != predicted_Y[i]:\n",
    "\t\t#print(test_res._values[i],predicted_Y[i],Y_test_proba[i])\n",
    "\t\terror += 1 \n",
    "print(\"Error,\",error)\n",
    "print(\"F3,\",fbeta_score(test_res, predicted_Y, average='binary', beta=3))\n",
    "recall = recall_score(test_res,predicted_Y)\n",
    "precision = precision_score(test_res,predicted_Y)\n",
    "print(\"precision,\",precision)\n",
    "print(\"recall,\",recall)\n",
    "\n",
    "\n",
    "pcm(clf,test_pca,test_res)\n",
    "\n",
    "Real_pca = pca.transform(unknown_data)\n",
    "\n",
    "predicted_Y = clf.predict(Real_pca)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_dtc = GaussianNB()\n",
    "\n",
    "clf_dtc.fit(train_data,train_res)\n",
    "predicted_Y = clf_dtc.predict(test_data)\n",
    "Y_test_proba = clf_dtc.predict_proba(test_data)[:,1]\n",
    "\n",
    "#predicted_Y = [ i>0.2 for i in Y_test_proba]\n",
    "\n",
    "print(\"acc,\",acc(test_res,predicted_Y))\n",
    "print(\"bas,\",bas(test_res,predicted_Y))\n",
    "error = 0\n",
    "for i in range(len(test_res)):\n",
    "\tif test_res._values[i] != predicted_Y[i]:\n",
    "\t\t#print(test_res._values[i],predicted_Y[i],Y_test_proba[i])\n",
    "\t\terror += 1 \n",
    "print(\"Error,\",error)\n",
    "print(\"F3,\",fbeta_score(test_res, predicted_Y, average='binary', beta=3))\n",
    "recall = recall_score(test_res,predicted_Y)\n",
    "precision = precision_score(test_res,predicted_Y)\n",
    "print(\"precision,\",precision)\n",
    "print(\"recall,\",recall)\n",
    "\n",
    "pcm(clf_dtc,test_data,test_res)\n",
    "\n",
    "\n",
    "predicted_Y = clf_dtc.predict(unknown_data)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicted_Y = clf.predict(Real_pca)\n",
    "print(len(predicted_Y), sum(predicted_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(predicted_Y)\n",
    "\n",
    "f = open(\"schmidt_laszlo_gnb.csv\",'w')\n",
    "\n",
    "f.write(\"Id,Predicted\\n\")\n",
    "for i,val in enumerate(predicted_Y):\n",
    "\tf.write(\"{},{}\\n\".format(i,val))\n",
    "\n",
    "f.flush()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "pca = pca.fit(train)\n",
    "a = pca.transform(train)\n",
    "print(pca.explained_variance_ratio_)\n",
    "\n",
    "print(len(train),\",\",len(a))\n",
    "#plt.scatter(a,y_test)\n",
    "#plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('python_env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2c04eb4a0b16f4d74363df0e3af9c29b1d83d6e0a755e6e140f7182eb118dcf6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
