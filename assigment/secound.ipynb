{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.decomposition import PCA,KernelPCA\n",
    "\n",
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier as DTC\n",
    "from sklearn.linear_model import LinearRegression as LR\n",
    "from sklearn.metrics import accuracy_score as acc\n",
    "from sklearn.metrics import balanced_accuracy_score as bas\n",
    "from sklearn.metrics import plot_confusion_matrix as pcm\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn import linear_model\n",
    "import sweetviz as sv\n",
    "\n",
    "\n",
    "def export(Y):\n",
    "\tglobal modell\n",
    "\tglobal method\n",
    "\n",
    "\t#len(Y)\n",
    "\t#print(modell.__name__)\n",
    "\t#print(method.__name__)\n",
    "\tfilename = modell.__class__.__name__ +\"_\"+ method.__name__ + \".csv\"\n",
    "\tprint(\"Exporting to\",filename)\n",
    "\tf = open(filename,'w')\n",
    "\n",
    "\tf.write(\"Id,Predicted\\n\")\n",
    "\tfor i,val in enumerate(Y):\n",
    "\t\tf.write(\"{},{}\\n\".format(i,val))\n",
    "\n",
    "\tf.flush()\n",
    "\tf.close()\n",
    "\n",
    "def perform_method_null(modell,train_x,train_y,test_x):\n",
    "\tprint(\"Forgot to select method...exiting\")\n",
    "\texit()\n",
    "\n",
    "\n",
    "modell = object\n",
    "method = perform_method_null\n",
    "train_x = None\n",
    "train_y = None\n",
    "test_x = None\n",
    "test_y = None\n",
    "\n",
    "#select\n",
    "#train\n",
    "#test\n",
    "#deploy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(isdeploy = False):\n",
    "\tprint(\"Loading data..\")\n",
    "\ttrain_x = pd.read_csv('data/X_train.csv')\n",
    "\ttrain_y = pd.read_csv('data/y_train.csv')\n",
    "\ttrain_x.drop('Id', inplace=True, axis=1) # staticly drop the id collumn\n",
    "\ttrain_y.drop('Id', inplace=True, axis=1) # staticly drop the id collumn\n",
    "\tif isdeploy:\n",
    "\t\ttest_x = pd.read_csv('data/X_test.csv')\n",
    "\t\ttest_x.drop('Id', inplace=True, axis=1) # staticly drop the id collumn\n",
    "\t\treturn train_x, test_x, train_y,None # here there are no test_y\n",
    "\telse:\n",
    "\t\treturn train_test_split(train_x, train_y,test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SeparateHistValue(data):\n",
    "\tvisited = []\n",
    "\tvalues = []\n",
    "\thists = []\n",
    "\tfor col in data.columns:\n",
    "\t\tsimbol = col[0:2]\n",
    "\t\tif simbol in visited:\n",
    "\t\t\tcontinue\n",
    "\t\tvisited.append(simbol)\n",
    "\t\t#print(simbol)\n",
    "\t\tsim_cols = []\n",
    "\t\t#get all similar colum\n",
    "\t\tfor col2 in data.columns:\n",
    "\t\t\tif simbol in col2:\n",
    "\t\t\t\tsim_cols.append(col2)\n",
    "\t\tif len(sim_cols) > 1:\n",
    "\t\t\thists.extend(sim_cols)\n",
    "\t\telse:\n",
    "\t\t\tvalues.append(sim_cols[0])\n",
    "\treturn values,hists\n",
    "\n",
    "\n",
    "def HistNormalize(data):\n",
    "\tprint(\"HistNormalize\")\n",
    "\tvisited = []\n",
    "\n",
    "\tfor col in data.columns:\n",
    "\t\tsimbol = col[0:2]\n",
    "\t\tif simbol in visited:\n",
    "\t\t\tcontinue\n",
    "\t\tvisited.append(simbol)\n",
    "\t\t#print(simbol)\n",
    "\t\tsim_cols = []\n",
    "\t\t#get all similar colum\n",
    "\t\tfor col2 in data.columns:\n",
    "\t\t\tif simbol in col2:\n",
    "\t\t\t\tsim_cols.append(col2)\n",
    "\t\t\n",
    "\t\tif len(sim_cols) > 1:\n",
    "\t\t\tselected_block = data[sim_cols] \n",
    "\t\t\tselected_block = selected_block.div(selected_block.sum(axis=1),axis = 0)\n",
    "\t\t\tdata[sim_cols] = selected_block \n",
    "\n",
    "\treturn data \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_method_0(modell,train_x,test_x,train_y):\n",
    "\tprint(\"Performing method 0...\")\n",
    "\t\n",
    "\tprint(\"Preprocess..\")\n",
    "\ttrain_x = train_x.fillna(0)\n",
    "\ttest_x = test_x.fillna(0)\n",
    "\n",
    "\ttrain_x = HistNormalize(train_x)\n",
    "\ttest_x = HistNormalize(test_x)\n",
    "\n",
    "\ttrain_x = train_x.fillna(0) # we do it again do to 0 division\n",
    "\ttest_x = test_x.fillna(0)\n",
    "\n",
    "\tvalues,hists = SeparateHistValue(train_x)\n",
    "\n",
    "\t#select only histograms\n",
    "\t#train_x = train_x[hists]\n",
    "\t#test_x = test_x[hists]\n",
    "\t\n",
    "\n",
    "\tprint(\"Training..\")\n",
    "\tmodell.fit(train_x,train_y)\n",
    "\tprint(\"Predicting..\")\n",
    "\tY = modell.predict(test_x)\n",
    "\n",
    "\treturn Y\n",
    "method = perform_method_0\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment pipline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Experiment...\")\n",
    "train_x, test_x, train_y, test_y = load_data(False)\n",
    "if modell is object:\n",
    "\traise Exception(\"Forgot to select a modell..\")\n",
    "Y = method(modell,train_x, test_x, train_y)\n",
    "\n",
    "print(\"Evalueting\")\n",
    "\n",
    "print(\"acc,\",acc(test_y,Y))\n",
    "#print(\"bas,\",bas(test_y,Y))\n",
    "#pcm(modell,test_x,test_y)\n",
    "error = 0\n",
    "for i in range(len(test_y)):\n",
    "\tif test_y._values[i] != Y[i]:\n",
    "\t\t#print(test_y._values[i],Y[i],Y_test_proba[i])\n",
    "\t\terror += 1 \n",
    "print(\"Error count =\",error,\"/\",len(test_y))\n",
    "print(\"F3,\",fbeta_score(test_y, Y, average='binary', beta=3))\n",
    "recall = recall_score(test_y,Y)\n",
    "precision = precision_score(test_y,Y)\n",
    "print(\"precision,\",precision)\n",
    "print(\"recall,\",recall)\n",
    "#print(\"f_measure\",f_measure(recall,precision))\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deployment pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deploy...\n",
      "Loading data..\n",
      "Performing method 0...\n",
      "Preprocess..\n",
      "HistNormalize\n",
      "HistNormalize\n",
      "Training..\n",
      "Predicting..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Programing\\Gitted\\Datamining_course\\python_env\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exporting to GaussianNB_perform_method_0.csv\n"
     ]
    }
   ],
   "source": [
    "print(\"Deploy...\")\n",
    "train_x, test_x, train_y, test_y = load_data(True)\n",
    "if modell is object:\n",
    "\tprint(\"Forgot to select a modell, exiting..\")\n",
    "\texit()\n",
    "Y = method(modell,train_x, test_x, train_y)\n",
    "export(Y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modell = DTC(random_state=42,criterion = \"entropy\",min_samples_split = 50,max_features = \"sqrt\")#\"entropy\"  #log_loss #gini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "modell = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modell = KNeighborsClassifier(2,algorithm=\"auto\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = x_train.columns\n",
    "\n",
    "new_cols = []\n",
    "for c in col:\n",
    "\ttag = c.split('_')[0]\n",
    "\tcount=0\n",
    "\tfor name in col:\n",
    "\t\tif tag in name:\n",
    "\t\t\tcount+=1\n",
    "\tif count == 1:\n",
    "\t\tnew_cols.append(c) \n",
    "\t\t#print(c)\n",
    "\t#if [c==x for x in col]\n",
    "\n",
    "train_data = x_train[new_cols]\n",
    "test_data = x_test[new_cols]\n",
    "\n",
    "print(len(new_cols))\n",
    "\n",
    "unknown_data = unknown[new_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(x_train.columns))\n",
    "#print(x_train.columns)\n",
    "#does the same as next\n",
    "#x_train.nunique()\n",
    "#print(\"isnasum \",x_train.isna().sum())\n",
    "headers = []\n",
    "\n",
    "for col in x_train.columns:\n",
    "\t#if not \"000\" in col:\n",
    "\t\t#print(col,(x_train[col] == 0).sum())\n",
    "\t\t#continue\n",
    "\t\t#print(col)\n",
    "\tif (x_train[col] == 0).sum() < len(x_train)/2:\n",
    "\t\t#print(col,(x_train[col] == 0).sum(),len(x_train[col].value_counts()))\n",
    "\t\theaders.append(col)\n",
    "\n",
    "#for col in x_train.columns:\n",
    "#\tif len(x_train[col].value_counts()) < len(x_train)/2:\n",
    "#\t\theaders.append(col)\n",
    "\t\t#print(col,len(x_train[col].value_counts()))\n",
    "\n",
    "\n",
    "train_data = x_train[headers]\n",
    "test_data = x_test[headers]\n",
    "\n",
    "print(len(headers))\n",
    "\n",
    "unknown_data = unknown[headers]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dont run this\n",
    "train_data = x_train\n",
    "test_data = x_test\n",
    "unknown_data = unknown"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting modell with parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modell = DTC(random_state=42,criterion = \"entropy\",min_samples_split = 50,max_features = \"sqrt\")#\"entropy\"  #log_loss #gini"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification model tester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "modell\n",
    "clf_dtc.fit(train_data,train_res)\n",
    "predicted_Y = clf_dtc.predict(test_data)\n",
    "#Y_test_proba = clf_dtc.predict_proba(test_data)[:,1]\n",
    "\n",
    "#predicted_Y = [ i>0.2 for i in Y_test_proba]\n",
    "\n",
    "print(\"acc,\",acc(test_res,predicted_Y))\n",
    "print(\"bas,\",bas(test_res,predicted_Y))\n",
    "pcm(clf_dtc,test_data,test_res)\n",
    "error = 0\n",
    "for i in range(len(test_res)):\n",
    "\tif test_res._values[i] != predicted_Y[i]:\n",
    "\t\t#print(test_res._values[i],predicted_Y[i],Y_test_proba[i])\n",
    "\t\terror += 1 \n",
    "print(\"Error,\",error)\n",
    "print(\"F3,\",fbeta_score(test_res, predicted_Y, average='binary', beta=3))\n",
    "recall = recall_score(test_res,predicted_Y)\n",
    "precision = precision_score(test_res,predicted_Y)\n",
    "print(\"precision,\",precision)\n",
    "print(\"recall,\",recall)\n",
    "#print(\"f_measure\",f_measure(recall,precision))\n",
    "\n",
    "predicted_Y = clf_dtc.predict(unknown_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clf_dtc = DTC(random_state=42,criterion = \"entropy\",min_samples_split = 50,max_features = \"sqrt\")#\"entropy\"  #log_loss #gini\n",
    "clf_dtc.fit(train_data,train_res)\n",
    "predicted_Y = clf_dtc.predict(test_data)\n",
    "#Y_test_proba = clf_dtc.predict_proba(test_data)[:,1]\n",
    "\n",
    "#predicted_Y = [ i>0.2 for i in Y_test_proba]\n",
    "\n",
    "print(\"acc,\",acc(test_res,predicted_Y))\n",
    "print(\"bas,\",bas(test_res,predicted_Y))\n",
    "pcm(clf_dtc,test_data,test_res)\n",
    "error = 0\n",
    "for i in range(len(test_res)):\n",
    "\tif test_res._values[i] != predicted_Y[i]:\n",
    "\t\t#print(test_res._values[i],predicted_Y[i],Y_test_proba[i])\n",
    "\t\terror += 1 \n",
    "print(\"Error,\",error)\n",
    "print(\"F3,\",fbeta_score(test_res, predicted_Y, average='binary', beta=3))\n",
    "recall = recall_score(test_res,predicted_Y)\n",
    "precision = precision_score(test_res,predicted_Y)\n",
    "print(\"precision,\",precision)\n",
    "print(\"recall,\",recall)\n",
    "#print(\"f_measure\",f_measure(recall,precision))\n",
    "\n",
    "predicted_Y = clf_dtc.predict(unknown_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_knc = KNeighborsClassifier(2,algorithm=\"auto\") \n",
    "#DTC(random_state=42,criterion = \"gini\",min_samples_split = 50,max_features = \"sqrt\")#\"entropy\"  #log_loss\n",
    "\n",
    "clf_knc.fit(train_data,train_res)\n",
    "predicted_Y = clf_knc.predict(test_data)\n",
    "\n",
    "print(\"acc,\",acc(test_res,predicted_Y))\n",
    "print(\"bas,\",bas(test_res,predicted_Y))\n",
    "error = 0\n",
    "for i in range(len(test_res)):\n",
    "\tif test_res._values[i] != predicted_Y[i]:\n",
    "\t\t#print(test_res._values[i],predicted_Y[i],Y_test_proba[i])\n",
    "\t\terror += 1 \n",
    "print(\"Error,\",error)\n",
    "print(\"F3,\",fbeta_score(test_res, predicted_Y, average='binary', beta=3))\n",
    "recall = recall_score(test_res,predicted_Y)\n",
    "precision = precision_score(test_res,predicted_Y)\n",
    "print(\"precision,\",precision)\n",
    "print(\"recall,\",recall)\n",
    "pcm(clf_knc,test_data,test_res)\n",
    "\n",
    "\n",
    "#predicted_Y = clf.predict(Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100,bootstrap=True)\n",
    "clf.fit(train_data,train_res)\n",
    "predicted_Y = clf.predict(test_data)\n",
    "Y_test_proba = clf.predict_proba(test_data)[:,1]\n",
    "\n",
    "print(\"acc,\",acc(test_res,predicted_Y))\n",
    "print(\"bas,\",bas(test_res,predicted_Y))\n",
    "error = 0\n",
    "for i in range(len(test_res)):\n",
    "\tif test_res._values[i] != predicted_Y[i]:\n",
    "\t\t#print(test_res._values[i],predicted_Y[i],Y_test_proba[i])\n",
    "\t\terror += 1 \n",
    "print(\"Error,\",error)\n",
    "print(\"F3,\",fbeta_score(test_res, predicted_Y, average='binary', beta=3))\n",
    "recall = recall_score(test_res,predicted_Y)\n",
    "precision = precision_score(test_res,predicted_Y)\n",
    "print(\"precision,\",precision)\n",
    "print(\"recall,\",recall)\n",
    "pcm(clf,test_data,test_res)\n",
    "predicted_Y = clf.predict(unknown_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=10)\n",
    "pca = pca.fit(train_data)\n",
    "train_pca = pca.transform(train_data)\n",
    "\n",
    "test_pca = pca.transform(test_data)\n",
    "\n",
    "#Real_pca = pca.transform(Test)\n",
    "\n",
    "#reg = linear_model.BayesianRidge()\n",
    "\n",
    "#plt.scatter(train_pca)\n",
    "plt.scatter(train_pca[:,1],train_pca[:,6],c=train_res)\n",
    "plt.show()\n",
    "\n",
    "#clf = DTC(random_state=42,criterion = \"gini\",min_samples_split = 100,max_features = \"sqrt\")#\"entropy\"  #log_loss\n",
    "#clf = clf.fit(train_pca,test_res)\n",
    "#reg = reg.fit(train_pca,y_train)\n",
    "\n",
    "#print(reg.coef_)\n",
    "\n",
    "#predicted_Y = clf.predict(test_pca)\n",
    "#predicted_Y = reg.predict(test_pca)\n",
    "#Y_test_proba = clf.predict_proba(test_pca)[:,1]\n",
    "\n",
    "\n",
    "#print(acc(test_res,predicted_Y))\n",
    "\n",
    "#print(bas(test_res,predicted_Y,adjusted=True))\n",
    "#print(bas(test_res,predicted_Y,adjusted=False))\n",
    "\n",
    "#pcm(clf,train_pca,y_train)\n",
    "\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=20)\n",
    "clf.fit(train_pca,train_res)\n",
    "predicted_Y = clf.predict(test_pca)\n",
    "Y_test_proba = clf.predict_proba(test_pca)[:,1]\n",
    "\n",
    "#predicted_Y = [ i>0.2 for i in Y_test_proba]\n",
    "\n",
    "\n",
    "print(\"acc,\",acc(test_res,predicted_Y))\n",
    "print(\"bas,\",bas(test_res,predicted_Y))\n",
    "error = 0\n",
    "for i in range(len(test_res)):\n",
    "\tif test_res._values[i] != predicted_Y[i]:\n",
    "\t\t#print(test_res._values[i],predicted_Y[i],Y_test_proba[i])\n",
    "\t\terror += 1 \n",
    "print(\"Error,\",error)\n",
    "print(\"F3,\",fbeta_score(test_res, predicted_Y, average='binary', beta=3))\n",
    "recall = recall_score(test_res,predicted_Y)\n",
    "precision = precision_score(test_res,predicted_Y)\n",
    "print(\"precision,\",precision)\n",
    "print(\"recall,\",recall)\n",
    "\n",
    "\n",
    "pcm(clf,test_pca,test_res)\n",
    "\n",
    "Real_pca = pca.transform(unknown_data)\n",
    "\n",
    "predicted_Y = clf.predict(Real_pca)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_dtc = GaussianNB()\n",
    "\n",
    "clf_dtc.fit(x_train,train_res)\n",
    "predicted_Y = clf_dtc.predict(x_test)\n",
    "Y_test_proba = clf_dtc.predict_proba(x_test)[:,1]\n",
    "\n",
    "#predicted_Y = [ i>0.2 for i in Y_test_proba]\n",
    "\n",
    "print(\"acc,\",acc(test_res,predicted_Y))\n",
    "print(\"bas,\",bas(test_res,predicted_Y))\n",
    "error = 0\n",
    "for i in range(len(test_res)):\n",
    "\tif test_res._values[i] != predicted_Y[i]:\n",
    "\t\t#print(test_res._values[i],predicted_Y[i],Y_test_proba[i])\n",
    "\t\terror += 1 \n",
    "print(\"Error,\",error)\n",
    "print(\"F3,\",fbeta_score(test_res, predicted_Y, average='binary', beta=3))\n",
    "recall = recall_score(test_res,predicted_Y)\n",
    "precision = precision_score(test_res,predicted_Y)\n",
    "print(\"precision,\",precision)\n",
    "print(\"recall,\",recall)\n",
    "\n",
    "pcm(clf_dtc,test_data,test_res)\n",
    "\n",
    "\n",
    "#predicted_Y = clf_dtc.predict(unknown_data)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicted_Y = clf.predict(Real_pca)\n",
    "print(len(predicted_Y), sum(predicted_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(predicted_Y)\n",
    "\n",
    "f = open(\"schmidt_laszlo_gnb.csv\",'w')\n",
    "\n",
    "f.write(\"Id,Predicted\\n\")\n",
    "for i,val in enumerate(predicted_Y):\n",
    "\tf.write(\"{},{}\\n\".format(i,val))\n",
    "\n",
    "f.flush()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "pca = pca.fit(train)\n",
    "a = pca.transform(train)\n",
    "print(pca.explained_variance_ratio_)\n",
    "\n",
    "print(len(train),\",\",len(a))\n",
    "#plt.scatter(a,y_test)\n",
    "#plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('python_env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2c04eb4a0b16f4d74363df0e3af9c29b1d83d6e0a755e6e140f7182eb118dcf6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
